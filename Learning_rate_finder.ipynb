{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ],
      "metadata": {
        "id": "sWlkkeyhUGz3"
      },
      "id": "sWlkkeyhUGz3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()\n"
      ],
      "metadata": {
        "id": "3XiSzDEzUTkO"
      },
      "id": "3XiSzDEzUTkO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "HsDDT_e7__lx"
      },
      "id": "HsDDT_e7__lx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4852040-5472-410e-842b-8bf690f702ee",
      "metadata": {
        "id": "c4852040-5472-410e-842b-8bf690f702ee"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Flatten , Dropout\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e176a10-6f36-4868-9b97-e9c8ef9cf8db",
      "metadata": {
        "id": "0e176a10-6f36-4868-9b97-e9c8ef9cf8db"
      },
      "outputs": [],
      "source": [
        "conv_base = VGG16(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(150,150,3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ad6edc-ecb0-417a-8adc-b7a317ca1094",
      "metadata": {
        "id": "d6ad6edc-ecb0-417a-8adc-b7a317ca1094"
      },
      "outputs": [],
      "source": [
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac2213c-1d26-498c-bb24-3c9812f7d3a5",
      "metadata": {
        "id": "6ac2213c-1d26-498c-bb24-3c9812f7d3a5"
      },
      "outputs": [],
      "source": [
        "model  = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9771583-f6d2-4318-b2c2-1574f1dc3a9f",
      "metadata": {
        "id": "e9771583-f6d2-4318-b2c2-1574f1dc3a9f"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2bf236d-2802-442a-ad3a-90ec997aea4f",
      "metadata": {
        "id": "a2bf236d-2802-442a-ad3a-90ec997aea4f"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable  = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f277499-33ee-48cc-bc77-13f92b7c6753",
      "metadata": {
        "id": "4f277499-33ee-48cc-bc77-13f92b7c6753"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "# Specify the directory containing all the images\n",
        "data_directory = r'/content/dogs_vs_cats/train'\n",
        "\n",
        "# Split the data into training and validation datasets\n",
        "training_ds = image_dataset_from_directory(\n",
        "    directory=data_directory,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=16,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    validation_split=0.1,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_ds = image_dataset_from_directory(\n",
        "    directory=data_directory,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=16,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    validation_split=0.1,\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35cd89c-5c6c-485a-aaff-4fd847d352cb",
      "metadata": {
        "id": "f35cd89c-5c6c-485a-aaff-4fd847d352cb"
      },
      "outputs": [],
      "source": [
        "def Normalizaion(image,label):\n",
        "    image  = tf.cast(image/255.,tf.float32)\n",
        "    return image,label\n",
        "\n",
        "training_ds = training_ds.map(Normalizaion)\n",
        "validation_ds  = validation_ds.map(Normalizaion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e037f91-18ac-4e7c-81ec-a1c5e342296a",
      "metadata": {
        "id": "4e037f91-18ac-4e7c-81ec-a1c5e342296a"
      },
      "outputs": [],
      "source": [
        "# Learning rate finder variables\n",
        "lrs = []\n",
        "losses = []\n",
        "min_lr = 1e-7  # Minimum learning rate\n",
        "max_lr = 1     # Maximum learning rate\n",
        "lr_factor = (max_lr / min_lr) ** (1 / len(training_ds))  # Exponential increment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7115d57a-b6cb-4a7e-a3aa-d94837d12ea6",
      "metadata": {
        "id": "7115d57a-b6cb-4a7e-a3aa-d94837d12ea6"
      },
      "outputs": [],
      "source": [
        "# Use a custom training loop to find the optimal learning rate\n",
        "optimizer = Adam(learning_rate=min_lr)\n",
        "loss_fn = keras.losses.BinaryCrossentropy()\n",
        "train_loss_metric = keras.metrics.Mean()\n",
        "\n",
        "for batch_idx, (images, labels) in enumerate(training_ds):\n",
        "    # Update learning rate\n",
        "    lr = min_lr * (lr_factor ** batch_idx)\n",
        "    optimizer.learning_rate.assign(lr)\n",
        "    lrs.append(lr)\n",
        "\n",
        "    # Forward pass\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_fn(labels, predictions)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss_metric.update_state(loss)\n",
        "\n",
        "    # Record the loss\n",
        "    losses.append(train_loss_metric.result().numpy())\n",
        "\n",
        "    # Stop once we've covered enough steps\n",
        "    if lr > max_lr:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6470348-7474-4761-9033-fa2db663cc4b",
      "metadata": {
        "id": "f6470348-7474-4761-9033-fa2db663cc4b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02995c13-1176-4f4f-bfc0-e85cacd76135",
      "metadata": {
        "id": "02995c13-1176-4f4f-bfc0-e85cacd76135"
      },
      "outputs": [],
      "source": [
        "# Plot the learning rate finder results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lrs, losses)\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate (Log Scale)')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Learning Rate Finder')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e265e1ae-1c8c-4190-8b8d-322c99c73482",
      "metadata": {
        "id": "e265e1ae-1c8c-4190-8b8d-322c99c73482"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001) ,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af6d672-11be-427a-b191-b197583b6a3d",
      "metadata": {
        "id": "2af6d672-11be-427a-b191-b197583b6a3d"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "history = model.fit(\n",
        "    training_ds,\n",
        "    epochs=30,\n",
        "    validation_data=validation_ds\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d93d7961-d76c-4fd9-8fe0-da901b268f6f",
      "metadata": {
        "id": "d93d7961-d76c-4fd9-8fe0-da901b268f6f"
      },
      "outputs": [],
      "source": [
        "model.save(r'C:\\model_save\\dog_cat\\dog_cat_woa.h5')\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b48e67b7-f2dc-44f3-b0be-8dc3e677097b",
      "metadata": {
        "id": "b48e67b7-f2dc-44f3-b0be-8dc3e677097b"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], color='red', label='train')\n",
        "plt.plot(history.history['val_accuracy'], color='blue', label='validation')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy: Training vs Validation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3df05c-5671-4a68-a7c2-348ce5d425fc",
      "metadata": {
        "id": "8d3df05c-5671-4a68-a7c2-348ce5d425fc"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'],color='red',label='train')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.title('Model loss: Training vs Validation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fae7acd-e71b-4e95-8e72-ed364139a9f3",
      "metadata": {
        "id": "2fae7acd-e71b-4e95-8e72-ed364139a9f3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load your trained model (replace the path with your model's file path)\n",
        "model = tf.keras.models.load_model(r'C:\\model_save\\dog_cat\\dog_cat_woa.h5')\n",
        "\n",
        "# Function to preprocess the image and classify it using the custom model\n",
        "def classify_image(img_path):\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(150, 150))  # Resize to model input size\n",
        "    img_array = image.img_to_array(img)  # Convert image to numpy array\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = img_array / 255.0  # Normalize the image\n",
        "\n",
        "    # Predict using your trained model\n",
        "    prediction = model.predict(img_array)  # Sigmoid returns a single probability value\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n",
        "\n",
        "    # Print output based on the model's prediction\n",
        "    if prediction[0][0] < 0.5:\n",
        "        print(\"Predicted: Cat\")\n",
        "    else:\n",
        "        print(\"Predicted: Dog\")\n",
        "\n",
        "# Folder containing images\n",
        "image_folder = r'G:\\image_dataset\\valid'\n",
        "\n",
        "# Loop through the images in the folder and classify each\n",
        "for img_name in os.listdir(image_folder):\n",
        "    img_path = os.path.join(image_folder, img_name)\n",
        "    if img_name.lower().endswith(('png', 'jpg', 'jpeg')):\n",
        "        print(f\"Classifying {img_name}...\")\n",
        "        classify_image(img_path)\n",
        "        print(\"=\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ebc8261-34b0-404e-90b1-a188e8c53274",
      "metadata": {
        "id": "6ebc8261-34b0-404e-90b1-a188e8c53274"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Specify the base directory containing your image data\n",
        "data_directory = r'G:\\image_dataset\\cat_or_dog'\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Data augmentation for training data with validation split\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.1  # Split 20% for validation\n",
        ")\n",
        "\n",
        "# Normalization for validation data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae362698-a1aa-4e53-89f5-ce5e5dbdf2a9",
      "metadata": {
        "id": "ae362698-a1aa-4e53-89f5-ce5e5dbdf2a9"
      },
      "outputs": [],
      "source": [
        "# Flow from directory for training set (80% of the data)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_directory,  # Directory for both training and validation data\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    seed=42,\n",
        "    class_mode='binary',  # Since it's binary classification (cat or dog)\n",
        "    subset='training'  # Specifies this is the training part of the data\n",
        ")\n",
        "\n",
        "# Flow from directory for validation set (20% of the data)\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    directory=data_directory,  # Directory for both training and validation data\n",
        "    target_size=(150, 150),\n",
        "    batch_size=batch_size,\n",
        "    seed=42,\n",
        "    class_mode='binary',  # Since it's binary classification (cat or dog)\n",
        "    subset='validation'  # Specifies this is the validation part of the data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30b2f3a9-51af-4a9b-a893-6d6e09189df6",
      "metadata": {
        "id": "30b2f3a9-51af-4a9b-a893-6d6e09189df6"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001) ,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9740bccc-557a-475b-b817-a750da2e2af3",
      "metadata": {
        "id": "9740bccc-557a-475b-b817-a750da2e2af3"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbec5a3a-03b7-4222-8bde-6914dd3475ad",
      "metadata": {
        "id": "cbec5a3a-03b7-4222-8bde-6914dd3475ad"
      },
      "outputs": [],
      "source": [
        "model.save(r'C:\\model_save\\dog_cat\\dog_cat_wa.h5')\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73712253-af81-4db5-a819-8bb4c1c35b60",
      "metadata": {
        "id": "73712253-af81-4db5-a819-8bb4c1c35b60"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], color='red', label='train')\n",
        "plt.plot(history.history['val_accuracy'], color='blue', label='validation')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy: Training vs Validation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a704c47-94e9-403d-8eef-1132e36bcd20",
      "metadata": {
        "id": "2a704c47-94e9-403d-8eef-1132e36bcd20"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'],color='red',label='train')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.title('Model loss: Training vs Validation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e79ce5-4d6f-4fb9-bb03-01ddccaaecaf",
      "metadata": {
        "id": "40e79ce5-4d6f-4fb9-bb03-01ddccaaecaf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load your trained model (replace the path with your model's file path)\n",
        "model = tf.keras.models.load_model(r'C:\\model_save\\dog_cat\\dog_cat_wa.h5')\n",
        "\n",
        "# Function to preprocess the image and classify it using the custom model\n",
        "def classify_image(img_path):\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(150, 150))  # Resize to model input size\n",
        "    img_array = image.img_to_array(img)  # Convert image to numpy array\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = img_array / 255.0  # Normalize the image\n",
        "\n",
        "    # Predict using your trained model\n",
        "    prediction = model.predict(img_array)  # Sigmoid returns a single probability value\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n",
        "\n",
        "    # Print output based on the model's prediction\n",
        "    if prediction[0][0] < 0.5:\n",
        "        print(\"Predicted: Cat\")\n",
        "    else:\n",
        "        print(\"Predicted: Dog\")\n",
        "\n",
        "# Folder containing images\n",
        "image_folder = r'G:\\image_dataset\\valid'\n",
        "\n",
        "# Loop through the images in the folder and classify each\n",
        "for img_name in os.listdir(image_folder):\n",
        "    img_path = os.path.join(image_folder, img_name)\n",
        "    if img_name.lower().endswith(('png', 'jpg', 'jpeg')):\n",
        "        print(f\"Classifying {img_name}...\")\n",
        "        classify_image(img_path)\n",
        "        print(\"=\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a22fd6-3f10-4637-8dfe-66cb3b331499",
      "metadata": {
        "id": "a0a22fd6-3f10-4637-8dfe-66cb3b331499"
      },
      "outputs": [],
      "source": [
        "model  = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5a35b82-e755-4645-a1a6-bc899d119566",
      "metadata": {
        "id": "e5a35b82-e755-4645-a1a6-bc899d119566"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e30c3a-1f1f-45f3-bd59-e2e3c244488b",
      "metadata": {
        "id": "69e30c3a-1f1f-45f3-bd59-e2e3c244488b"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001) ,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3896f18d-a2eb-4637-b733-4d93498f329d",
      "metadata": {
        "id": "3896f18d-a2eb-4637-b733-4d93498f329d"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "469d8603-ccb2-4eab-8bdf-5aa4f29aed7a",
      "metadata": {
        "id": "469d8603-ccb2-4eab-8bdf-5aa4f29aed7a"
      },
      "outputs": [],
      "source": [
        "model.save(r'C:\\model_save\\dog_cat\\dog_cat_wa_dropout.h5')\n",
        "print(\"Model saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb7c1d91-d9e7-4670-b802-e7126c49210d",
      "metadata": {
        "id": "eb7c1d91-d9e7-4670-b802-e7126c49210d"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], color='red', label='train')\n",
        "plt.plot(history.history['val_accuracy'], color='blue', label='validation')\n",
        "plt.legend()\n",
        "plt.title('Model Accuracy: Training vs Validation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9780923b-420d-4d8a-a20c-525a9a81ceeb",
      "metadata": {
        "id": "9780923b-420d-4d8a-a20c-525a9a81ceeb"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'],color='red',label='train')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.title('Model loss: Training vs Validation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f39e0b-566b-4d03-be96-067754d2f948",
      "metadata": {
        "id": "f3f39e0b-566b-4d03-be96-067754d2f948"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load your trained model (replace the path with your model's file path)\n",
        "model = tf.keras.models.load_model(r'C:\\model_save\\dog_cat\\dog_cat_wa_dropout.h5')\n",
        "\n",
        "# Function to preprocess the image and classify it using the custom model\n",
        "def classify_image(img_path):\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=(150, 150))  # Resize to model input size\n",
        "    img_array = image.img_to_array(img)  # Convert image to numpy array\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = img_array / 255.0  # Normalize the image\n",
        "\n",
        "    # Predict using your trained model\n",
        "    prediction = model.predict(img_array)  # Sigmoid returns a single probability value\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n",
        "\n",
        "    # Print output based on the model's prediction\n",
        "    if prediction[0][0] < 0.5:\n",
        "        print(\"Predicted: Cat\")\n",
        "    else:\n",
        "        print(\"Predicted: Dog\")\n",
        "\n",
        "# Folder containing images\n",
        "image_folder = r'G:\\image_dataset\\valid'\n",
        "\n",
        "# Loop through the images in the folder and classify each\n",
        "for img_name in os.listdir(image_folder):\n",
        "    img_path = os.path.join(image_folder, img_name)\n",
        "    if img_name.lower().endswith(('png', 'jpg', 'jpeg')):\n",
        "        print(f\"Classifying {img_name}...\")\n",
        "        classify_image(img_path)\n",
        "        print(\"=\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd4c580-27fa-45a9-b61a-55f5b6d24a3d",
      "metadata": {
        "id": "2cd4c580-27fa-45a9-b61a-55f5b6d24a3d"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Simulating random learning rate vs. loss plots\n",
        "x = np.logspace(-7, 0, 100)  # Learning rates (log scale)\n",
        "y1 = 1 / (1 + np.exp(-3 * (np.log10(x) + 3))) + np.random.uniform(-0.05, 0.05, size=100)  # Sharp drop, plateau\n",
        "y2 = 1 / (1 + np.exp(-2 * (np.log10(x) + 1))) + 0.1 * np.log10(x)  # Diverging loss\n",
        "y3 = 1 / (1 + np.exp(-2 * (np.log10(x) + 2))) + np.random.uniform(-0.03, 0.03, size=100)  # Smooth loss curve\n",
        "\n",
        "# Plotting the graphs\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Plot 1: Optimal range found\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(x, y1, label=\"Loss vs. Learning Rate\", color='blue')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate (Log Scale)')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Learning Rate Finder - Sharp Drop, Plateau Found')\n",
        "plt.axvline(x=1e-4, color='green', linestyle='--', label='Recommended LR')\n",
        "plt.legend()\n",
        "\n",
        "# Plot 2: Diverging loss\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(x, y2, label=\"Loss vs. Learning Rate\", color='red')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate (Log Scale)')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Learning Rate Finder - Diverging Loss at High LR')\n",
        "plt.axvline(x=1e-3, color='orange', linestyle='--', label='Safe Lower LR')\n",
        "plt.legend()\n",
        "\n",
        "# Plot 3: Smooth curve with gradual improvement\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(x, y3, label=\"Loss vs. Learning Rate\", color='purple')\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Learning Rate (Log Scale)')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Learning Rate Finder - Smooth Gradual Improvement')\n",
        "plt.axvline(x=3e-3, color='green', linestyle='--', label='Optimal LR')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}